Emergent reasoning in large language models is supported by several recent publications. "Response: Emergent analogical reasoning in large language models" directly provides evidence for emergent analogical reasoning. Other papers, such as "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models" and "Advancing Reasoning in Large Language Models: Promising Methods and Approaches," suggest that LLMs possess some form of reasoning capabilities that researchers are actively trying to understand and improve. The paper "Implicit Reasoning in Transformers is Reasoning through Shortcuts" explores the mechanisms behind reasoning in transformers, the architecture underlying many LLMs, suggesting that even if reasoning is achieved through shortcuts, it is still a form of implicit reasoning. Finally, "Enhance Reasoning Ability of Visual-Language Models via Large Language Models" indirectly supports the hypothesis by demonstrating that LLMs can be used to enhance the reasoning abilities of other models.